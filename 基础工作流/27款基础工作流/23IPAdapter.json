{
  "last_node_id": 27,
  "last_link_id": 48,
  "nodes": [
    {
      "id": 11,
      "type": "VAELoader",
      "pos": [
        137,
        535
      ],
      "size": {
        "0": 361.8415832519531,
        "1": 58
      },
      "flags": {},
      "order": 0,
      "mode": 0,
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            2
          ],
          "shape": 3,
          "label": "VAE",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader"
      },
      "widgets_values": [
        "vae-ft-mse-840000-ema-pruned.safetensors"
      ]
    },
    {
      "id": 3,
      "type": "CLIPTextEncode",
      "pos": [
        616,
        491
      ],
      "size": {
        "0": 400,
        "1": 200
      },
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 4,
          "label": "clip"
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            6
          ],
          "shape": 3,
          "label": "CONDITIONING",
          "slot_index": 0
        }
      ],
      "title": "CLIP Text Encode (Prompt)负向提示词",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "blurry, horror,"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 1,
      "type": "CheckpointLoader|pysssss",
      "pos": [
        133,
        322
      ],
      "size": {
        "0": 379.3333740234375,
        "1": 128
      },
      "flags": {},
      "order": 1,
      "mode": 0,
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            47
          ],
          "shape": 3,
          "label": "MODEL",
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            3,
            4
          ],
          "shape": 3,
          "label": "CLIP",
          "slot_index": 1
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": null,
          "shape": 3,
          "label": "VAE"
        }
      ],
      "properties": {
        "Node name for S&R": "CheckpointLoader|pysssss"
      },
      "widgets_values": [
        {
          "content": "1.5\\dreamshaper_631BakedVae.safetensors",
          "image": "checkpoints/1.5\\dreamshaper_631BakedVae.png"
        },
        "[none]"
      ]
    },
    {
      "id": 25,
      "type": "IPAdapterModelLoader",
      "pos": [
        620,
        780
      ],
      "size": [
        380.6666259765625,
        58
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "outputs": [
        {
          "name": "IPADAPTER",
          "type": "IPADAPTER",
          "links": [
            46
          ],
          "shape": 3,
          "label": "IPADAPTER",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterModelLoader"
      },
      "widgets_values": [
        "ip-adapter-full-face_sd15.bin"
      ],
      "color": "#323",
      "bgcolor": "#535"
    },
    {
      "id": 26,
      "type": "CLIPVisionLoader",
      "pos": [
        623,
        900
      ],
      "size": [
        376.6666259765625,
        61.33343505859375
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "outputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "links": [
            45
          ],
          "shape": 3,
          "label": "CLIP_VISION",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPVisionLoader"
      },
      "widgets_values": [
        "SD1.5\\model.safetensors"
      ],
      "color": "#323",
      "bgcolor": "#535"
    },
    {
      "id": 8,
      "type": "EmptyLatentImage",
      "pos": [
        1112,
        571
      ],
      "size": {
        "0": 315,
        "1": 106
      },
      "flags": {},
      "order": 4,
      "mode": 0,
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            8
          ],
          "shape": 3,
          "label": "LATENT",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        512,
        512,
        1
      ]
    },
    {
      "id": 12,
      "type": "VAEDecode",
      "pos": [
        1900,
        180
      ],
      "size": {
        "0": 210,
        "1": 46
      },
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 9,
          "label": "samples"
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 2,
          "label": "vae"
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            10
          ],
          "shape": 3,
          "label": "IMAGE",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      }
    },
    {
      "id": 13,
      "type": "SaveImage",
      "pos": [
        2150,
        180
      ],
      "size": {
        "0": 527.9220581054688,
        "1": 474.5712585449219
      },
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 10,
          "label": "images"
        }
      ],
      "properties": {},
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 14,
      "type": "Note",
      "pos": [
        95,
        20
      ],
      "size": [
        423.31654901123056,
        222.43866296386722
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "基础 IPADAPTER\n===============\n\n选择模型时要小心！\n\nIPAdapter Model 必须与 CLIP Vision 编码器匹配，当然还有大模型。\n\n所有 SD15 模型和所有以“vit-h”结尾的模型，都使用 SD15 CLIP Vision。\n\n其中 SDXL 模型和所有以“vit-g”结尾的模型，都使用 SDXL CLIP Vision。\n\nPLUS模型使用更多的token，并且更强大。LIGHT模型的影响非常小。\nFACE和FULL-FACE只是为了描述面孔（它们不是换脸！）"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 9,
      "type": "KSampler",
      "pos": [
        1550,
        180
      ],
      "size": {
        "0": 315,
        "1": 474
      },
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 48,
          "label": "model"
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 43,
          "label": "positive"
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 6,
          "label": "negative"
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 8,
          "label": "latent_image"
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            9
          ],
          "shape": 3,
          "label": "LATENT",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        317154649884515,
        "randomize",
        25,
        6,
        "ddim",
        "sgm_uniform",
        1
      ]
    },
    {
      "id": 4,
      "type": "LoadImage",
      "pos": [
        185,
        781
      ],
      "size": {
        "0": 315,
        "1": 314.0000305175781
      },
      "flags": {},
      "order": 6,
      "mode": 0,
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            44
          ],
          "shape": 3,
          "label": "IMAGE",
          "slot_index": 0
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null,
          "shape": 3,
          "label": "MASK"
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "woman4.png",
        "image"
      ],
      "color": "#323",
      "bgcolor": "#535"
    },
    {
      "id": 2,
      "type": "CLIPTextEncode",
      "pos": [
        613,
        209
      ],
      "size": {
        "0": 400,
        "1": 200
      },
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 3,
          "label": "clip"
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            43
          ],
          "shape": 3,
          "label": "CONDITIONING",
          "slot_index": 0
        }
      ],
      "title": "CLIP Text Encode (Prompt)正向提示词",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "beautiful renaissance girl, detailed,"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 27,
      "type": "IPAdapterApply",
      "pos": [
        1114,
        781
      ],
      "size": {
        "0": 315,
        "1": 258
      },
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "ipadapter",
          "type": "IPADAPTER",
          "link": 46,
          "label": "ipadapter"
        },
        {
          "name": "clip_vision",
          "type": "CLIP_VISION",
          "link": 45,
          "label": "clip_vision"
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 44,
          "label": "image"
        },
        {
          "name": "model",
          "type": "MODEL",
          "link": 47,
          "label": "model"
        },
        {
          "name": "attn_mask",
          "type": "MASK",
          "link": null,
          "label": "attn_mask"
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            48
          ],
          "shape": 3,
          "label": "MODEL",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterApply"
      },
      "widgets_values": [
        0.85,
        0,
        "original",
        0.2,
        1,
        false
      ],
      "color": "#323",
      "bgcolor": "#535"
    }
  ],
  "links": [
    [
      2,
      11,
      0,
      12,
      1,
      "VAE"
    ],
    [
      3,
      1,
      1,
      2,
      0,
      "CLIP"
    ],
    [
      4,
      1,
      1,
      3,
      0,
      "CLIP"
    ],
    [
      6,
      3,
      0,
      9,
      2,
      "CONDITIONING"
    ],
    [
      8,
      8,
      0,
      9,
      3,
      "LATENT"
    ],
    [
      9,
      9,
      0,
      12,
      0,
      "LATENT"
    ],
    [
      10,
      12,
      0,
      13,
      0,
      "IMAGE"
    ],
    [
      43,
      2,
      0,
      9,
      1,
      "CONDITIONING"
    ],
    [
      44,
      4,
      0,
      27,
      2,
      "IMAGE"
    ],
    [
      45,
      26,
      0,
      27,
      1,
      "CLIP_VISION"
    ],
    [
      46,
      25,
      0,
      27,
      0,
      "IPADAPTER"
    ],
    [
      47,
      1,
      0,
      27,
      3,
      "MODEL"
    ],
    [
      48,
      27,
      0,
      9,
      0,
      "MODEL"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {},
  "version": 0.4
}